{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50a3964d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,Conv1D,Conv2D,MaxPooling2D,MaxPooling1D,Flatten,Bidirectional\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef42c69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "mlflow_path = pathlib.Path('../../mlruns').resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3bce5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(mlflow_path)\n",
    "mlflow.tensorflow.autolog()\n",
    "tf.keras.utils.set_random_seed(42)  # sets seeds for base-python, numpy and tf\n",
    "tf.config.experimental.enable_op_determinism()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e61421a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2022 = pd.read_csv('../../Tweet_Sentiment/THYAO/2022_final.csv').drop(['fark', 'tweet_count'], axis= 1).set_index('Unnamed: 0').sort_index()\n",
    "df_2021 = pd.read_csv('../../Tweet_Sentiment/THYAO/2021_final.csv').drop(['fark', 'tweet_count'], axis= 1).set_index('Unnamed: 0').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0648028f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>şimdi</th>\n",
       "      <th>açılış</th>\n",
       "      <th>avg_polar</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-04</th>\n",
       "      <td>12.68</td>\n",
       "      <td>12.97</td>\n",
       "      <td>0.715789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-05</th>\n",
       "      <td>12.62</td>\n",
       "      <td>12.64</td>\n",
       "      <td>0.729469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-06</th>\n",
       "      <td>12.69</td>\n",
       "      <td>12.73</td>\n",
       "      <td>0.752577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-07</th>\n",
       "      <td>12.68</td>\n",
       "      <td>12.74</td>\n",
       "      <td>0.684729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-08</th>\n",
       "      <td>12.82</td>\n",
       "      <td>12.75</td>\n",
       "      <td>0.711538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-26</th>\n",
       "      <td>98.80</td>\n",
       "      <td>101.20</td>\n",
       "      <td>0.672098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-27</th>\n",
       "      <td>99.40</td>\n",
       "      <td>99.10</td>\n",
       "      <td>0.638142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-28</th>\n",
       "      <td>96.95</td>\n",
       "      <td>98.70</td>\n",
       "      <td>0.634686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-31</th>\n",
       "      <td>101.30</td>\n",
       "      <td>97.70</td>\n",
       "      <td>0.630435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-01</th>\n",
       "      <td>102.40</td>\n",
       "      <td>102.30</td>\n",
       "      <td>0.634361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>458 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             şimdi  açılış  avg_polar\n",
       "Unnamed: 0                           \n",
       "2021-01-04   12.68   12.97   0.715789\n",
       "2021-01-05   12.62   12.64   0.729469\n",
       "2021-01-06   12.69   12.73   0.752577\n",
       "2021-01-07   12.68   12.74   0.684729\n",
       "2021-01-08   12.82   12.75   0.711538\n",
       "...            ...     ...        ...\n",
       "2022-10-26   98.80  101.20   0.672098\n",
       "2022-10-27   99.40   99.10   0.638142\n",
       "2022-10-28   96.95   98.70   0.634686\n",
       "2022-10-31  101.30   97.70   0.630435\n",
       "2022-11-01  102.40  102.30   0.634361\n",
       "\n",
       "[458 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df_2022, df_2021]).sort_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08953981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler = scaler.fit(df.iloc[:-30, :])\n",
    "df_for_training_scaled = scaler.transform(df)\n",
    "\n",
    "scaler_for_inference = MinMaxScaler()\n",
    "scaler_for_inference.fit(pd.DataFrame(df.iloc[:-30,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa363f85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02770428, 0.03244157, 0.53188611],\n",
       "       [0.02677043, 0.02736777, 0.55893537],\n",
       "       [0.02785992, 0.02875154, 0.60463083],\n",
       "       ...,\n",
       "       [1.33929961, 1.35055351, 0.37151184],\n",
       "       [1.40700389, 1.33517835, 0.36310474],\n",
       "       [1.42412451, 1.40590406, 0.37086895]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_for_training_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa0bc514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainX shape = (453, 5, 3).\n",
      "TrainY shape = (453, 1, 1).\n"
     ]
    }
   ],
   "source": [
    "#Empty lists to be populated using formatted training data\n",
    "trainX = []\n",
    "trainY = []\n",
    "\n",
    "n_future = 1   # Number of days we want to look into the future based on the past days.\n",
    "n_past = 5  # Number of past days we want to use to predict the future.\n",
    "\n",
    "#Reformat input data into a shape: (n_samples x timesteps x n_features)\n",
    "#In my example, my df_for_training_scaled has a shape (12823, 5)\n",
    "#12823 refers to the number of data points and 5 refers to the columns (multi-variables).\n",
    "for i in range(n_past, len(df_for_training_scaled) - n_future +1):\n",
    "    trainX.append(df_for_training_scaled[i - n_past:i, 0:df.shape[1]])\n",
    "    trainY.append(df_for_training_scaled[i + n_future - 1:i + n_future,[0]])\n",
    "\n",
    "trainX, trainY = np.array(trainX), np.array(trainY)\n",
    "\n",
    "print('TrainX shape = {}.'.format(trainX.shape))\n",
    "print('TrainY shape = {}.'.format(trainY.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5875688c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((423, 5, 2), (423, 5, 3))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_lstm_without_twitter, X_test_lstm_without_twitter, y_train_lstm_without_twitter, y_test_lstm_without_twitter = train_test_split(trainX[:,:,:-1], trainY, test_size=30, shuffle=False)\n",
    "\n",
    "X_train_lstm_twitter, X_test_lstm_twitter, y_train_lstm_twitter, y_test_lstm_twitter = train_test_split(trainX, trainY, test_size=30, shuffle=False)\n",
    "\n",
    "X_train_lstm_without_twitter.shape,X_train_lstm_twitter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17350618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape):\n",
    "    tf.keras.utils.set_random_seed(42)  # sets seeds for base-python, numpy and tf\n",
    "    cnn_lstm_model = Sequential()\n",
    "\n",
    "    cnn_lstm_model.add(Conv1D(filters=128, kernel_size=2, strides=1, padding='valid', input_shape=input_shape))\n",
    "    cnn_lstm_model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "\n",
    "    cnn_lstm_model.add(Conv1D(filters=64, kernel_size=2, strides=1, padding='valid'))\n",
    "    cnn_lstm_model.add(MaxPooling1D(pool_size=1, strides=2))\n",
    "    # cnn_lstm_model.add(MaxPooling1D(pool_size=1, strides=2))\n",
    "\n",
    "    cnn_lstm_model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
    "    cnn_lstm_model.add(Dropout(0.2))\n",
    "    cnn_lstm_model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
    "    cnn_lstm_model.add(Dropout(0.2))\n",
    "\n",
    "    cnn_lstm_model.add(Dense(32, activation='relu'))\n",
    "\n",
    "\n",
    "    cnn_lstm_model.add(Dense(trainY.shape[2], activation='relu'))\n",
    "\n",
    "    # cnn_lstm_model.build(input_shape=(trainX.shape[0], trainX.shape[1], trainX.shape[2]))\n",
    "\n",
    "    cnn_lstm_model.compile(optimizer='adam', loss='mse')\n",
    "    cnn_lstm_model.summary()\n",
    "    return cnn_lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b304fb4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 4, 128)            640       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 2, 128)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 1, 64)             16448     \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 1, 64)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 1, 512)           657408    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1, 512)            0         \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 1, 512)           1574912   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1, 512)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1, 32)             16416     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,265,857\n",
      "Trainable params: 2,265,857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_2 (Conv1D)           (None, 4, 128)            896       \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 2, 128)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 1, 64)             16448     \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 1, 64)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 1, 512)           657408    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1, 512)            0         \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (None, 1, 512)           1574912   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1, 512)            0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1, 32)             16416     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,266,113\n",
      "Trainable params: 2,266,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/12/16 17:33:38 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'fba4d90b46bd4bb4b40bb4657b05c121', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 0.0869WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0288s vs `on_train_batch_end` time: 0.0460s). Check your callbacks.\n",
      "7/7 [==============================] - 10s 57ms/step - loss: 0.0795\n",
      "Epoch 2/60\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.0145\n",
      "Epoch 3/60\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0074\n",
      "Epoch 4/60\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0021\n",
      "Epoch 5/60\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0015\n",
      "Epoch 6/60\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0012\n",
      "Epoch 7/60\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 7.8163e-04\n",
      "Epoch 8/60\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 7.4141e-04\n",
      "Epoch 9/60\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 7.6139e-04\n",
      "Epoch 10/60\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 6.3845e-04\n",
      "Epoch 11/60\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 6.7453e-04\n",
      "Epoch 12/60\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 7.6096e-04\n",
      "Epoch 13/60\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 6.1583e-04\n",
      "Epoch 14/60\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 6.4101e-04\n",
      "Epoch 15/60\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 6.7092e-04\n",
      "Epoch 16/60\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 7.0000e-04\n",
      "Epoch 17/60\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 7.1692e-04\n",
      "Epoch 18/60\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 7.0703e-04\n",
      "Epoch 19/60\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 6.2137e-04\n",
      "Epoch 20/60\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 5.3166e-04\n",
      "Epoch 21/60\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 6.3113e-04\n",
      "Epoch 22/60\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 6.8533e-04\n",
      "Epoch 23/60\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 5.9038e-04\n",
      "Epoch 24/60\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 6.9012e-04\n",
      "Epoch 25/60\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 5.6216e-04\n",
      "Epoch 26/60\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 6.2868e-04\n",
      "Epoch 27/60\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 6.5194e-04\n",
      "Epoch 28/60\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 6.2887e-04\n",
      "Epoch 29/60\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 6.4569e-04\n",
      "Epoch 30/60\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 5.2133e-04\n",
      "Epoch 31/60\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 5.4081e-04\n",
      "Epoch 32/60\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 6.0301e-04\n",
      "Epoch 33/60\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 7.4807e-04\n",
      "Epoch 34/60\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 5.1710e-04\n",
      "Epoch 35/60\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 5.7554e-04\n",
      "Epoch 36/60\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 6.0291e-04\n",
      "Epoch 37/60\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 6.4372e-04\n",
      "Epoch 38/60\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 5.9260e-04\n",
      "Epoch 39/60\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 6.6263e-04\n",
      "Epoch 40/60\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 7.4535e-04\n",
      "Epoch 41/60\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 6.4495e-04\n",
      "Epoch 42/60\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 8.0985e-04\n",
      "Epoch 43/60\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 8.5524e-04\n",
      "Epoch 44/60\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 8.7935e-04\n",
      "Epoch 45/60\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 7.7810e-04\n",
      "Epoch 46/60\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 7.0167e-04\n",
      "Epoch 47/60\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 5.8046e-04\n",
      "Epoch 48/60\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 5.9946e-04\n",
      "Epoch 49/60\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 6.6625e-04\n",
      "Epoch 50/60\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 8.5304e-04\n",
      "Epoch 51/60\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 8.7426e-04\n",
      "Epoch 52/60\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 7.1958e-04\n",
      "Epoch 53/60\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 4.8099e-04\n",
      "Epoch 54/60\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 5.6769e-04\n",
      "Epoch 55/60\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 5.3677e-04\n",
      "Epoch 56/60\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 6.2325e-04\n",
      "Epoch 57/60\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 6.8341e-04\n",
      "Epoch 58/60\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 6.1016e-04\n",
      "Epoch 59/60\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 6.4542e-04\n",
      "Epoch 60/60\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 5.1038e-04\n",
      "1/1 [==============================] - 1s 979ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/12/16 17:33:55 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"C:\\Users\\assas\\anaconda3\\envs\\tf\\lib\\site-packages\\mlflow\\tensorflow\\__init__.py:189: UserWarning: The pyfunc inference behavior of Keras models logged with signatures differs from the behavior of Keras models logged without signatures. Specifically, when a signature is present, passing a Pandas DataFrame as input to the pyfunc `predict()` API produces an `ndarray` (for single-output models) or a dictionary of `str -> ndarray`: (for multi-output models). In contrast, when a signature is *not* present, `predict()` produces a Pandas DataFrame output in response to a Pandas DataFrame input.\"\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\assas\\AppData\\Local\\Temp\\tmpqdxg5yq3\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\assas\\AppData\\Local\\Temp\\tmpqdxg5yq3\\model\\data\\model\\assets\n",
      "2022/12/16 17:34:27 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"C:\\Users\\assas\\anaconda3\\envs\\tf\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\n",
      "2022/12/16 17:34:28 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '6ca12324132b4ed3ad06853da9b25775', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "7/7 [==============================] - 4s 66ms/step - loss: 0.0808\n",
      "Epoch 2/60\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0140\n",
      "Epoch 3/60\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0055\n",
      "Epoch 4/60\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0030\n",
      "Epoch 5/60\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0019\n",
      "Epoch 6/60\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0015\n",
      "Epoch 7/60\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0012\n",
      "Epoch 8/60\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0010\n",
      "Epoch 9/60\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0010\n",
      "Epoch 10/60\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 8.6238e-04\n",
      "Epoch 11/60\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 8.3536e-04\n",
      "Epoch 12/60\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 8.7795e-04\n",
      "Epoch 13/60\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 7.4252e-04\n",
      "Epoch 14/60\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 7.2806e-04\n",
      "Epoch 15/60\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 7.1314e-04\n",
      "Epoch 16/60\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 7.5163e-04\n",
      "Epoch 17/60\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 7.7505e-04\n",
      "Epoch 18/60\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 8.5910e-04\n",
      "Epoch 19/60\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 6.7735e-04\n",
      "Epoch 20/60\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 5.8075e-04\n",
      "Epoch 21/60\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 6.8745e-04\n",
      "Epoch 22/60\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 7.3245e-04\n",
      "Epoch 23/60\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 6.0498e-04\n",
      "Epoch 24/60\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 8.1011e-04\n",
      "Epoch 25/60\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 5.3774e-04\n",
      "Epoch 26/60\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 6.3037e-04\n",
      "Epoch 27/60\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 6.0420e-04\n",
      "Epoch 28/60\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 5.8775e-04\n",
      "Epoch 29/60\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 5.3215e-04\n",
      "Epoch 30/60\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 5.4468e-04\n",
      "Epoch 31/60\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 5.3169e-04\n",
      "Epoch 32/60\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 5.6416e-04\n",
      "Epoch 33/60\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 7.6697e-04\n",
      "Epoch 34/60\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 5.1216e-04\n",
      "Epoch 35/60\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 5.9458e-04\n",
      "Epoch 36/60\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 5.9578e-04\n",
      "Epoch 37/60\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 6.9588e-04\n",
      "Epoch 38/60\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 5.8101e-04\n",
      "Epoch 39/60\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 5.8732e-04\n",
      "Epoch 40/60\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 6.2145e-04\n",
      "Epoch 41/60\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 5.6563e-04\n",
      "Epoch 42/60\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 7.3568e-04\n",
      "Epoch 43/60\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 8.6727e-04\n",
      "Epoch 44/60\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 9.4482e-04\n",
      "Epoch 45/60\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 7.7554e-04\n",
      "Epoch 46/60\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 7.0891e-04\n",
      "Epoch 47/60\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 5.7655e-04\n",
      "Epoch 48/60\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 4.9292e-04\n",
      "Epoch 49/60\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 4.7345e-04\n",
      "Epoch 50/60\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 5.4037e-04\n",
      "Epoch 51/60\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 6.0543e-04\n",
      "Epoch 52/60\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 6.6471e-04\n",
      "Epoch 53/60\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 4.4014e-04\n",
      "Epoch 54/60\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 6.2341e-04\n",
      "Epoch 55/60\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 7.4210e-04\n",
      "Epoch 56/60\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 7.8436e-04\n",
      "Epoch 57/60\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 7.2582e-04\n",
      "Epoch 58/60\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 5.8994e-04\n",
      "Epoch 59/60\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 6.0477e-04\n",
      "Epoch 60/60\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 4.7935e-04\n",
      "1/1 [==============================] - 1s 929ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/12/16 17:34:39 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"C:\\Users\\assas\\anaconda3\\envs\\tf\\lib\\site-packages\\mlflow\\tensorflow\\__init__.py:189: UserWarning: The pyfunc inference behavior of Keras models logged with signatures differs from the behavior of Keras models logged without signatures. Specifically, when a signature is present, passing a Pandas DataFrame as input to the pyfunc `predict()` API produces an `ndarray` (for single-output models) or a dictionary of `str -> ndarray`: (for multi-output models). In contrast, when a signature is *not* present, `predict()` produces a Pandas DataFrame output in response to a Pandas DataFrame input.\"\n"
     ]
    }
   ],
   "source": [
    "cnn_lstm_model_without_twitter=build_model((X_train_lstm_without_twitter.shape[1],X_train_lstm_without_twitter.shape[2]))\n",
    "cnn_lstm_model_twitter=build_model((X_train_lstm_twitter.shape[1],X_train_lstm_twitter.shape[2]))\n",
    "\n",
    "history_without_twitter = cnn_lstm_model_without_twitter.fit(X_train_lstm_without_twitter, y_train_lstm_without_twitter, epochs=60, batch_size=64, verbose=1)\n",
    "\n",
    "history_twitter = cnn_lstm_model_twitter.fit(X_train_lstm_twitter, y_train_lstm_twitter, epochs=60, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9687df",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(history_twitter.history['loss'], label='Training loss')\n",
    "plt.title('Training loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16d49f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dates= df.index[:X_train_lstm_without_twitter.shape[0]]\n",
    "#Make prediction\n",
    "training_prediction_without_twitter = cnn_lstm_model_without_twitter.predict(X_train_lstm_without_twitter)\n",
    "\n",
    "training_prediction_twitter = cnn_lstm_model_twitter.predict(X_train_lstm_twitter)\n",
    "\n",
    "training_prediction_without_twitter=training_prediction_without_twitter.reshape(training_prediction_without_twitter.shape[0], training_prediction_without_twitter.shape[2])\n",
    "\n",
    "training_prediction_twitter=training_prediction_twitter.reshape(training_prediction_twitter.shape[0], training_prediction_twitter.shape[2])\n",
    "\n",
    "y_train_pred_lstm_without_twitter = scaler_for_inference.inverse_transform(training_prediction_without_twitter)\n",
    "\n",
    "y_train_pred_lstm_twitter = scaler_for_inference.inverse_transform(training_prediction_twitter)\n",
    "\n",
    "y_train_lstm_reshaped_without_twitter=y_train_lstm_without_twitter.reshape(y_train_lstm_without_twitter.shape[0], y_train_lstm_without_twitter.shape[2])\n",
    "\n",
    "y_train_actual_lstm = scaler_for_inference.inverse_transform(y_train_lstm_reshaped_without_twitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf17284f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "from math import sqrt\n",
    "\n",
    "def plot_predictions_with_dates (type,twitter,dates,y_actual_lstm,y_pred_lstm):\n",
    "    predicted_features=['şimdi']\n",
    "    for i,predicted_feature in enumerate(predicted_features):\n",
    "        plt.figure(figsize=(15,6))\n",
    "        if twitter :\n",
    "            plt.title(f'LSTM {type} prediction of {predicted_feature} feature After adding twitter sentiment analysis')\n",
    "        else:\n",
    "            plt.title(f'LSTM {type} prediction of {predicted_feature} feature without twitter sentiment analysis')\n",
    "        sns.lineplot(x=dates, y=y_actual_lstm[:,i],label='Actual')\n",
    "        sns.lineplot(x=dates, y=y_pred_lstm[:, i], label='Predicted')\n",
    "        plt.show()\n",
    "        error=mean_squared_error(y_actual_lstm[:,i], y_pred_lstm[:, i])\n",
    "        print(f'Mean square error for {predicted_feature} ={error}')\n",
    "    print('Total mean square error', mean_squared_error(y_actual_lstm, y_pred_lstm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd259b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_dates= df.index[-X_test_lstm_without_twitter.shape[0]:]\n",
    "#Make prediction\n",
    "testing_prediction_without_twitter = cnn_lstm_model_without_twitter.predict(X_test_lstm_without_twitter)\n",
    "testing_prediction_twitter = cnn_lstm_model_twitter.predict(X_test_lstm_twitter)\n",
    "\n",
    "testing_prediction_without_twitter=testing_prediction_without_twitter.reshape(testing_prediction_without_twitter.shape[0], testing_prediction_without_twitter.shape[2])\n",
    "testing_prediction_twitter=testing_prediction_twitter.reshape(testing_prediction_twitter.shape[0], testing_prediction_twitter.shape[2])\n",
    "\n",
    "y_test_pred_lstm_without_twitter = scaler_for_inference.inverse_transform(testing_prediction_without_twitter)\n",
    "y_test_pred_lstm_twitter = scaler_for_inference.inverse_transform(testing_prediction_twitter)\n",
    "\n",
    "y_test_actual_lstm_reshaped_without_twitter=y_test_lstm_without_twitter.reshape(y_test_lstm_without_twitter.shape[0], y_test_lstm_without_twitter.shape[2])\n",
    "\n",
    "\n",
    "y_test_actual_lstm = scaler_for_inference.inverse_transform(y_test_actual_lstm_reshaped_without_twitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e08a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dates= df.index[:X_train_lstm_twitter.shape[0]]\n",
    "plot_predictions_with_dates('Training',False,training_dates,y_train_actual_lstm ,y_train_pred_lstm_without_twitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ae7698",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dates= df.index[:X_train_lstm_twitter.shape[0]]\n",
    "plot_predictions_with_dates('Training',True,training_dates,y_train_actual_lstm ,y_train_pred_lstm_twitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa6a6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions_with_dates('Testing',False,testing_dates,y_test_actual_lstm,y_test_pred_lstm_without_twitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca003f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions_with_dates('Testing',True,testing_dates,y_test_actual_lstm,y_test_pred_lstm_twitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3f840b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_model_twitter.save('cnn_lstm_twitter.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47d824c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump\n",
    "dump(scaler, open('in_scaler.pkl', 'wb'))\n",
    "dump(scaler_for_inference, open('out_scaler.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
