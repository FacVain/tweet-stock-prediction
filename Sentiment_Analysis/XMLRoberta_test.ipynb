{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 2e-5\n",
    "EPOCHS = 1\n",
    "BATCH_SIZE = 16\n",
    "MODEL = \"cardiffnlp/twitter-xlm-roberta-base\"\n",
    "MAX_TRAINING_EXAMPLES = -1 # set this to -1 if you want to use the whole training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./Multiple_sources/processed_train.csv').dropna()\n",
    "x_train = train['text']\n",
    "y_train, _ = train['label'].factorize()\n",
    "test = pd.read_csv('./Multiple_sources/processed_test.csv').dropna()\n",
    "x_test = test['text']\n",
    "y_test, _ = test['label'].factorize()\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=1, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "374539    içindeki zil kedimin epey topun pesinden gidip...\n",
       "383411    ürün bugün elime ulaştı french bulldog cinsi k...\n",
       "215734                      beğendim ambalajlı geldi tşkler\n",
       "432730    taş kağıt makasa forma kaybeden maldır amk hay...\n",
       "316221    Köyün yerleşime açık Bahçecik adında bir mezra...\n",
       "                                ...                        \n",
       "141501    Sezonun başında Şampiyonlar Ligi eleme maçları...\n",
       "226933    Ruhsal portreler kişilerin görülebilen özellik...\n",
       "232308             ürün güzel kurulumu kolay tavsiye ederim\n",
       "284265    Eski yapıların bulunduğu alan Kent Meydanı ola...\n",
       "399420                            kesinlikle tavsiye ederim\n",
       "Name: text, Length: 396576, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[y_train == 0] = 3\n",
    "y_train[y_train == 1] = 0\n",
    "y_train[y_train == 3] = 1\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              Kral akbaba dikkat çekici renklere sahiptir\n",
       "1        ısrarla korkutmayı başarıyor korku uzun bitmiy...\n",
       "2        Neşe Üzüntü köprünün kırılmaya başlamasıyla ge...\n",
       "3        i phone 5 ten sonra gene 4 ekranı tercih ettim...\n",
       "4            Beşinci sezonda diziye yeni oyuncular katıldı\n",
       "                               ...                        \n",
       "48960    Fransa bayrağı diğer kırmızı zeminden beyaz bi...\n",
       "48961    Yine aynı yıl türkü dalında Murat Çobanoğlu bi...\n",
       "48962                             Kurgunu skiyim oç evladı\n",
       "48963    Şarkı sonrasında Damian Marley tarafından sesl...\n",
       "48964    berrak bir ürün ancak kendi orijinal spigen ly...\n",
       "Name: text, Length: 48960, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 2, 0, 2], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.apply(lambda x: tokenizer(x, truncation=True, padding='max_length', max_length=128))\n",
    "x_val = x_val.apply(lambda x: tokenizer(x, truncation=True, padding='max_length', max_length=128)) \n",
    "x_test = x_test.apply(lambda x: tokenizer(x, truncation=True, padding=\"max_length\", max_length=128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [input_ids, attention_mask]\n",
       "1        [input_ids, attention_mask]\n",
       "2        [input_ids, attention_mask]\n",
       "3        [input_ids, attention_mask]\n",
       "4        [input_ids, attention_mask]\n",
       "                    ...             \n",
       "44059    [input_ids, attention_mask]\n",
       "44060    [input_ids, attention_mask]\n",
       "44061    [input_ids, attention_mask]\n",
       "44062    [input_ids, attention_mask]\n",
       "44063    [input_ids, attention_mask]\n",
       "Name: text, Length: 44064, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val.reset_index(drop=True, inplace=True)\n",
    "x_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_tok = 0\n",
    "for i in x_train:\n",
    "    if len(i['input_ids']) > max_tok:\n",
    "        max_tok = len(i['input_ids'])\n",
    "max_tok\n",
    "3549"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_tok = 0\n",
    "for i in x_val:\n",
    "    if len(i['input_ids']) > max_tok:\n",
    "        max_tok = len(i['input_ids'])\n",
    "max_tok\n",
    "2241"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_tok = 0\n",
    "for i in x_test:\n",
    "    if len(i['input_ids']) > max_tok:\n",
    "        max_tok = len(i['input_ids'])\n",
    "max_tok\n",
    "1331"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {\"input_ids\": torch.tensor(self.encodings[idx][\"input_ids\"])}\n",
    "        item['attention_mask'] = torch.tensor(self.encodings[idx][\"attention_mask\"])\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = MyDataset(x_train, y_train)\n",
    "val_dataset = MyDataset(x_val, y_val)\n",
    "test_dataset = MyDataset(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(x_train.to_list(), truncation=True, padding=True, max_length=128)\n",
    "val_encodings = tokenizer(x_val.to_list(), truncation=True, padding=True, max_length=128)\n",
    "test_encodings = tokenizer(x_test.to_list(), truncation=True, padding=True, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = MyDataset(train_encodings, y_train)\n",
    "val_dataset = MyDataset(val_encodings, y_val)\n",
    "test_dataset = MyDataset(test_encodings, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-xlm-roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',                   # output directory\n",
    "    num_train_epochs=EPOCHS,                  # total number of training epochs\n",
    "    per_device_train_batch_size=BATCH_SIZE,   # batch size per device during training\n",
    "    per_device_eval_batch_size=BATCH_SIZE,    # batch size for evaluation\n",
    "    warmup_steps=100,                         # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,                        # strength of weight decay\n",
    "    logging_dir='./logs',                     # directory for storing logs\n",
    "    logging_steps=10,                         # when to print log\n",
    ")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL, num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,                              # the instantiated 🤗 Transformers model to be trained\n",
    "    args=training_args,                       # training arguments, defined above\n",
    "    train_dataset=train_dataset,              # training dataset\n",
    "    eval_dataset=val_dataset                  # evaluation dataset\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 44064\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.959     0.972     0.965     23592\n",
      "           1      0.990     0.998     0.994     15382\n",
      "           2      0.883     0.809     0.844      5090\n",
      "\n",
      "    accuracy                          0.962     44064\n",
      "   macro avg      0.944     0.926     0.934     44064\n",
      "weighted avg      0.961     0.962     0.961     44064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Val set has not been used yet. Test set gives similar result.(Add Test result too when running again.) \n",
    "val_preds_raw, val_labels , _ = trainer.predict(val_dataset)\n",
    "val_preds = np.argmax(val_preds_raw, axis=-1)\n",
    "print(classification_report(val_labels, val_preds, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results/best_model\n",
      "Configuration saved in ./results/best_model\\config.json\n",
      "Model weights saved in ./results/best_model\\pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(\"./results/best_model\") # save best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 14\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[-2.7639523 ,  6.209841  , -3.5093257 ],\n",
       "       [ 3.3379538 , -4.2822948 , -0.07614036],\n",
       "       [-2.6974714 ,  6.151871  , -3.5292373 ],\n",
       "       [ 1.5008385 , -2.9210513 ,  0.7395926 ],\n",
       "       [ 2.81848   , -4.006406  ,  0.19193465],\n",
       "       [-0.7852182 ,  3.0212512 , -2.063731  ],\n",
       "       [-0.55728257, -3.1341426 ,  4.6073575 ],\n",
       "       [ 0.01268318,  0.98467207, -0.9847228 ],\n",
       "       [-0.84086907, -1.6498721 ,  3.7046628 ],\n",
       "       [-1.0766885 ,  3.684284  , -2.416834  ],\n",
       "       [-0.43949133, -3.2303922 ,  4.5779424 ],\n",
       "       [-0.7951734 ,  2.7179723 , -1.6944032 ],\n",
       "       [-0.79751134,  3.0040443 , -2.0193284 ],\n",
       "       [ 4.650012  , -3.9620986 , -1.5205253 ]], dtype=float32), label_ids=array([1, 2, 1, 2, 2, 2, 2, 2, 2, 0, 2, 0, 0, 0], dtype=int64), metrics={'test_loss': 1.9274097681045532, 'test_runtime': 0.2101, 'test_samples_per_second': 66.649, 'test_steps_per_second': 4.761})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "online_test = pd.Series(['Kurtuluş Savaşı İzmir in isgaliyle başlar, İzmirin kurtuluşu ile biter.',\n",
    "                        'Seçimi kaybedeceğini bilen bir hükümet, \"30 gün prim ödeyen herkes, yaşına bakılmaksızın ve derhal kişi başına düşen gelir kadar emekli aylığı almaya hak kazanır\" diye bir kanun çıkarsa, bu kanun bir kere çıktı, kazanılmış hak oldu, herkese bu ödeme yapılsın diyecek misin?',\n",
    "                        'Karınca kolonisi optimizasyonu her zaman iyi sonuç vermeyebilir.',\n",
    "                        'Siyasilere manifesto: Benim paramla ulufe dağıtma yarışına giresiniz diye vergi ödemiyorum.',\n",
    "                        'Ben ekonomideki cehaletin boyutlarını görünce artık yapıcı yıkımdan başka bir yol olmadığını anlıyorum. Maliyeti engellemek için tüm samimiyetimizle doğruyu söyledik ama artık popülizm tavan yapmış durumda. Hepimiz ödeyeceğiz bu maliyeti!',\n",
    "                        'Dünyanın en büyük üçüncü ekonomisini en uzun süre yönetmiş adam suikaste uğruyor ancak bu olay medyada çok az yer alıyor. Maktül bu kadar büyükken bu kadar cılız ses çıkması şaşırtıcı.',\n",
    "                        'Seni it oğlu köpek şerefsiz.',\n",
    "                        'Bunu tasvip etmiyorum.',\n",
    "                        'Çok kötü bir gelişme.',\n",
    "                        'Bu hiçte kötü değil.',\n",
    "                        'Rezalet.',\n",
    "                        'Hisse artışa geçti çabuk alın.',\n",
    "                        'Olley be bist100 uçtu.',\n",
    "                        'Bist100 tavsiye ederim kaçırmayın.'])\n",
    "online_test = online_test.apply(lambda x: tokenizer(x, truncation=True, padding='max_length', max_length=128))\n",
    "online_ds = MyDataset(online_test, [1, 2, 1, 2, 2, 2, 2, 2, 2, 0, 2, 0, 0, 0])\n",
    "trainer.predict(online_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 7\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[ 2.6527088 , -3.9112282 ,  0.28650457],\n",
       "       [ 2.181105  , -3.6231873 ,  0.5682687 ],\n",
       "       [ 0.96109605, -1.7998203 ,  0.33854768],\n",
       "       [-0.6710125 ,  2.2690775 , -1.4880042 ],\n",
       "       [ 0.840981  , -3.963299  ,  3.5903444 ],\n",
       "       [ 3.4300041 , -4.3258862 , -0.12243924],\n",
       "       [-0.94187367,  3.4066384 , -2.2870247 ]], dtype=float32), label_ids=array([0, 0, 0, 2, 0, 0, 0], dtype=int64), metrics={'test_loss': 1.6829805374145508, 'test_runtime': 0.186, 'test_samples_per_second': 37.626, 'test_steps_per_second': 5.375})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "online_test = pd.Series(['Arkadaşlar 1 yıldır değişmeyen takip listemin başarı oranım/ 100 durBöyle olunca aynısını değerli 😀😀😀trader...kopyala yapıştır misali takip listeleri olmuş  birebir😀😀 Ayıptır emektir ustanın biraz edep yahu edep.',\n",
    "                        'İki aya kalmaz yüzde %400 gidecek iki #hisse gelecek #bist100 500 rt gelecek mi #bist30',\n",
    "                        '#Bist100 #xu100 dolar bazlı; yeşil çizginin üstünde kaldı, yönünü yukarı çevirdi. Pembe çizgiyi boşlukla aşacağı, son yılların en güçlü rallisinin eşiğinde olabilir. Kısa vadeli hedefi 273. Orta vadeli hedefi 324. Yatırım tavsiyesi değildir. #Elliott',\n",
    "                        'Bu hafta, yatırım araçlarından #borsa yatırımcıya kaybettirirken, #altın ve #dolar kazandırdı.Hafta içinde en düşük 3.048,67 puanı, en yüksek 3.319,14 puanı gören #bist100 endeksi haftayı %3,10 kayıpla 3.179,99 puandan tamamladı.',\n",
    "                        '#BORSA Çenem düştü azıcık konuştum ister izleyin ister izlemeyin Sonra gidip uçan balonlara binin',\n",
    "                        'Bugün akşam size pazartesinin tavanını yazacağım.Tavan hissem için bol BEĞENİ ve RT ile destek verin.Yeni 🔒 KİLİT hissemi bu akşam paylaşacağım🚀🚀🚀🚀🔒🔒🔒🔒#borsa #bist100 #tavan #rally',\n",
    "                        'Yükseliş trendine geçerek ilk direnç 30.62 seviyelerini deneyip tekrar düşüş yaşayan #EREGL yatay olarak seyir göstermektedir.  Tekrar düşüş yaşaması durumunda 29.96 ve 29.66 destek seviyelerini test etmesi muhtemeldir.'])\n",
    "online_test = online_test.apply(lambda x: tokenizer(x, truncation=True, padding='max_length', max_length=128))\n",
    "online_ds = MyDataset(online_test, [0, 0, 0, 2, 0, 0, 0])\n",
    "trainer.predict(online_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
